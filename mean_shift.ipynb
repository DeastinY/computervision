{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Shift\n",
    "#### Basic Implementation\n",
    "The following two functions find_peak and meanshift execute the basic mean shift algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import requests\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from scipy.io import loadmat\n",
    "from scipy import spatial\n",
    "from sklearn.datasets import *\n",
    "from IPython.core.display import clear_output\n",
    "from util import log_progress\n",
    "%matplotlib inline\n",
    "pylab.rcParams['figure.figsize'] = 16, 12\n",
    "sys.setrecursionlimit(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load  and visualize sample data\n",
    "The matrix is loaded into a numpy array of dimensions (2000, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/segbench/BSDS300/html/dataset/images/color/181091.html\n",
    "https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/segbench/BSDS300/html/dataset/images/color/55075.html\n",
    "https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/segbench/BSDS300/html/dataset/images/color/368078.html\n",
    "\"\"\"\n",
    "SAMPLE_DATA = loadmat(\"pts.mat\")['data'].transpose()\n",
    "img_path = Path('images')\n",
    "IMG_A = cv2.imread(str(img_path / \"a.jpg\"))\n",
    "IMG_B = cv2.imread(str(img_path / \"b.jpg\"))\n",
    "IMG_C = cv2.imread(str(img_path / \"c.jpg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Utility functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cached_tree = None\n",
    "def get_neighbours(data, point, r):\n",
    "    global cached_tree\n",
    "    tree = spatial.KDTree(data) if cached_tree is None else cached_tree\n",
    "    return tree.query_ball_point(point, r)\n",
    "\n",
    "def get_neighbours_cdist(data, point, r):\n",
    "    distances = spatial.distance.cdist(np.array([point]), data)[0]\n",
    "    return data[np.where(distances < r)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_peak(data, point, r, t = 0.01):\n",
    "    def calc_new_shift(data, point, r):\n",
    "        return data[get_neighbours(data, point, r)].mean(axis=0)\n",
    "    \n",
    "    dist = t\n",
    "    while dist >= t:\n",
    "        peak = calc_new_shift(data, point, r)\n",
    "        dist = spatial.distance.euclidean(peak, point)\n",
    "        point = peak\n",
    "    return peak\n",
    "\n",
    "def meanshift(data, r):\n",
    "    peaks, points, point_peaks = [], [], []\n",
    "    for point in log_progress(data, 1, len(data)):\n",
    "        peak = find_peak(data, point, r)\n",
    "        # Match peak to possible neighbours. Use cdist because we have only few peaks\n",
    "        neighbours = get_neighbours_cdist(np.array(peaks), peak, r/2.) if len(peaks) > 0 else []\n",
    "        if len(neighbours) > 1:\n",
    "            peak = neighbours[0]\n",
    "        else:\n",
    "            peaks.append(peak)\n",
    "        points.append(point)\n",
    "        point_peaks.append(np.where(peaks==peak)[0][0])\n",
    "    return np.array(peaks), np.array(points), np.array(point_peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_peak_opt(data, point, r, t = 0.01):\n",
    "    def calc_new_shift(data, point, r):\n",
    "        return data[get_neighbours(data, point, r)].mean(axis=0)\n",
    "    \n",
    "    dist = t\n",
    "    while dist >= t:\n",
    "        peak = calc_new_shift(data, point, r)\n",
    "        dist = spatial.distance.euclidean(peak, point)\n",
    "        point = peak\n",
    "    return peak\n",
    "\n",
    "def meanshift_opt(data, r):\n",
    "    peaks, point_peaks = [], np.zeros(data.shape[0], dtype='int16')-1\n",
    "    for i, point in log_progress(enumerate(data), every=100, size=len(data)):\n",
    "        if point_peaks[i] != -1:\n",
    "            continue\n",
    "        peak = find_peak(data, point, r)\n",
    "        # Match peak to possible neighbours. Use cdist because we have only few peaks\n",
    "        peak_neighbours = get_neighbours_cdist(np.array(peaks), peak, r/2.) if len(peaks) > 0 else []\n",
    "        if len(peak_neighbours) > 1:\n",
    "            peak = neighbours[0]\n",
    "        else:\n",
    "            peaks.append(peak)\n",
    "        # Basin of Attraction\n",
    "        neighbours = get_neighbours(data, peak, r)\n",
    "        print(neighbours)\n",
    "        point_peaks[neighbours] = np.where(peaks == peak)[0]\n",
    "    return np.array(peaks), point_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def image_segment(image, r, scale=0.05):\n",
    "    # preprocess the image\n",
    "    image = cv2.resize(image, None, fx = scale, fy = scale)\n",
    "    orig_img = np.array(image)\n",
    "    image = cv2.GaussianBlur(image, (5,5), 5.0)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    image = image.reshape(image.shape[0]*image.shape[1], image.shape[2])\n",
    "    print(\"Image has {} points\".format(image.shape))\n",
    "    peaks, point_peaks = meanshift_opt(image, r)\n",
    "    print(\"Found {} peaks !\".format(len(peaks)))\n",
    "    # convert back to show format\n",
    "    converted_peaks = cv2.cvtColor(np.array([peaks[:, 0:3]], dtype=np.uint8), cv2.COLOR_LAB2BGR)[0]\n",
    "    im = converted_peaks[point_peaks]\n",
    "    im = im.reshape(orig_img.shape[0], orig_img.shape[1], orig_img.shape[2])\n",
    "    plt.imshow(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Execute the meanshift function\n",
    "Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualize(image, r, func):\n",
    "    peaks, _ = func(image, r)\n",
    "    print(\"Found {} peaks in {} points !\".format(len(peaks), image.shape))\n",
    "    fig = plt.figure(figsize=(20, 20))\n",
    "    ax = fig.add_subplot(111, projection=\"3d\")\n",
    "    ax.scatter(*peaks.transpose(), c='black', s=100)\n",
    "    ax.scatter(*image.transpose(), c='blue', s=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image has (384, 3) points\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "690758139e914e3da3b568844146b6be"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[190, 191, 302, 303, 347, 363, 110, 236, 268, 285, 315, 111, 252, 267, 189, 205, 219, 235, 251, 331, 378, 173, 286, 188, 283, 287, 206, 221, 207, 269, 362, 94, 203, 234, 299, 95, 250, 157, 222, 237, 172, 253, 270, 1, 264, 0, 223, 248, 249, 265, 266, 218, 271]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ric/.local/lib/python3.5/site-packages/scipy/spatial/kdtree.py:291: RuntimeWarning: overflow encountered in ubyte_scalars\n",
      "  split = (maxval+minval)/2\n",
      "/home/ric/.local/lib/python3.5/site-packages/ipykernel_launcher.py:27: DeprecationWarning: assignment will raise an error in the future, most likely because your index result shape does not match the value array shape. You can use `arr.flat[index] = values` to keep the old behaviour.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[190, 191, 302, 303, 347, 363, 110, 236, 268, 285, 315, 111, 252, 267, 189, 205, 219, 235, 251, 331, 378, 173, 286, 188, 283, 287, 206, 221, 207, 269, 362, 94, 203, 234, 299, 95, 250, 157, 222, 237, 172, 253, 270, 1, 264, 0, 223, 248, 249, 265, 266, 218, 271]\n",
      "[346, 254, 141, 239, 232, 2, 187, 255, 202, 361, 376, 125, 280, 282, 3, 78, 281, 330, 156, 217, 375, 16, 17, 79, 360, 18, 171, 19, 314, 359, 109, 345, 298]\n",
      "[35, 296, 77, 87, 297, 36, 279, 313, 328, 60, 76, 124, 312, 86, 92, 108, 28, 62, 155, 170, 327, 103, 247, 44, 61, 358, 20, 4, 12, 34, 139, 295, 342, 27, 52, 63, 70, 59, 311, 69, 75, 104, 43, 45, 91]\n",
      "[47, 101, 121, 50, 30, 67, 293, 21, 73, 38, 55, 230, 277, 5, 14, 199, 324, 57, 134, 151, 261, 31, 41, 56, 308]\n",
      "[167, 183, 214, 49, 100, 150, 15, 245, 22, 40, 83, 198, 9, 48, 133, 292, 166, 182, 229, 66]\n",
      "[307, 99, 181, 197, 260, 165, 8, 148, 65, 7, 244, 82, 115, 164, 180, 228, 322, 291, 131, 306, 64]\n",
      "[4, 12, 34, 139, 295, 27, 52, 63, 70, 59, 311, 69, 75, 104, 231, 43, 45, 91, 123, 51, 102, 107, 119, 185, 11, 29, 71, 88, 154, 33, 68, 53, 85, 120, 341, 26, 90, 326, 13, 42, 169, 37, 58, 74, 138, 278, 32, 46, 106, 262, 54]\n",
      "[6, 116, 24, 323, 276, 149, 23, 132, 213, 307, 99, 181, 197, 260, 165, 8, 148]\n",
      "[54, 122, 294, 310, 325, 136, 184, 215, 10, 118, 135, 309, 72, 153, 89, 105, 246, 84, 137, 168, 47, 101, 121, 50, 30, 67, 152, 293, 21, 73, 38, 55, 230, 277]\n",
      "[5, 14, 199, 324, 57, 134, 151, 261, 31, 41, 56, 308, 117, 25, 39, 167, 183, 214, 49, 100, 150]\n",
      "[256, 257, 288, 240, 259, 272, 290, 241, 242, 243, 258, 273, 274, 289, 81, 210, 224, 225, 226, 227, 80, 96, 97, 98, 208, 209, 112, 113, 114, 194, 195, 129, 130, 177, 178, 192, 193, 128, 144, 145, 146, 160, 161, 162, 163, 176, 179]\n",
      "[254, 141, 239, 232, 2, 187, 255, 202, 361, 376, 125, 280, 282, 3, 78, 281, 330, 156, 217, 375, 16, 17, 79, 360, 18, 171, 19, 314, 359, 109, 345, 298]\n",
      "[335, 351, 383, 350, 367, 382, 319, 333, 349, 366, 316, 317, 334, 318, 332, 126, 143, 158, 159, 174, 175, 348, 365, 381, 127, 142, 364, 380, 204, 220, 300, 284, 301, 379, 190, 191, 302, 303, 347, 363, 110, 236, 268, 285, 315, 111, 252, 267, 189, 205, 219, 235, 251, 331, 378, 173, 286, 188, 283, 287]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-288-5ab0e7da9a6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#visualize(SAMPLE_DATA, r=5, func=meanshift_opt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimage_segment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMG_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-273-498adca93c81>\u001b[0m in \u001b[0;36mimage_segment\u001b[0;34m(image, r, scale)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Image has {} points\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mpeaks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoint_peaks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeanshift_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Found {} peaks !\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeaks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# convert back to show format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-287-9087c98c320b>\u001b[0m in \u001b[0;36mmeanshift_opt\u001b[0;34m(data, r)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mpeaks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeak\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# Basin of Attraction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mneighbours\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_neighbours\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpeak\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneighbours\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mpoint_peaks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mneighbours\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeaks\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mpeak\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-282-013c883ce9e1>\u001b[0m in \u001b[0;36mget_neighbours\u001b[0;34m(data, point, r)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0mcached_tree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspatial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKDTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcached_tree\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mcached_tree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery_ball_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_neighbours_cdist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ric/.local/lib/python3.5/site-packages/scipy/spatial/kdtree.py\u001b[0m in \u001b[0;36mquery_ball_point\u001b[0;34m(self, x, r, p, eps)\u001b[0m\n\u001b[1;32m    615\u001b[0m         \"\"\"\n\u001b[1;32m    616\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 617\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m             raise ValueError(\"Searching for a %d-dimensional point in a \"\n\u001b[1;32m    619\u001b[0m                              \"%d-dimensional KDTree\" % (x.shape[-1], self.m))\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "#visualize(SAMPLE_DATA, r=5, func=meanshift_opt)\n",
    "image_segment(IMG_A, r=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
